{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the main notebook for working on the capstone. Couple of things to do:\n",
    "\n",
    "- Build a function to clean your data - rows of text\n",
    "- Make the classification binary through renaming columns and feature engineering\n",
    "- Fill in the date for the article instead of the link\n",
    "-\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produced by: Aly Boolani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data source:***\n",
    "The data has been collected from https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset and you can download it here - hyperlink this \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Citations:***\n",
    "\n",
    "1. Ahmed H, Traore I, Saad S. “Detecting opinion spams and fake news using text classification”, Journal of Security and Privacy, Volume 1, Issue 1, Wiley, January/February 2018.\n",
    "\n",
    "2. Ahmed H, Traore I, Saad S. (2017) “Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques. In: Traore I., Woungang I., Awad A. (eds) Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments. ISDDC 2017. Lecture Notes in Computer Science, vol 10618. Springer, Cham (pp. 127-138)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains two types of articles fake and real news. This dataset has been collected from real world sources; the truthful articles were obtained by crawling articles from Reuters.com (A legitimate News website). As for the fake news articles, they were collected from a number of various sources. These fake news artiicles were collected from unrreliable websites that were flagged by Politifact (a fact-checking organization in the USA) and Wikipedia. The dataset contatins different types of articles on different topics, however, the majority of articles focus on political and world news topics. \n",
    "\n",
    "The dataset consists of two CSV files. The file ***True.csv*** contains more than 12,600 articles from reuter.com while the second file ***Fake.csv*** contains more than 12,600 artciles from different fake news outlet resources. Each article (data point) contains the following information: \n",
    "- Article Title\n",
    "- Article Text\n",
    "- Article Subject\n",
    "- Date the article was published on\n",
    "\n",
    "The overall data has been cleaned for us prior to downloading on it and contains articles from 2016 to 2017 and contains punctuations and mistakes that existed in the ***Fake.csv*** were kept as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| News      | Size   |      Subject     | Article size (breakdowns) |\n",
    "|-----------|--------|:----------------:|---------------------------|\n",
    "| Real-News | 21,417 | World News       | 10,145                    |\n",
    "|           |        | Political News   | 11,272                    |\n",
    "|           |        |                  |                           |\n",
    "| Fake-News | 23,481 | Government News  | 1,570                     |\n",
    "|           |        | Middle-east News | 778                       |\n",
    "|           |        | US News          | 783                       |\n",
    "|           |        | Left-News        | 4459                      |\n",
    "|           |        | Politics         | 6841                      |\n",
    "|           |        | News             | 9050                      |\n",
    "|           |        |                  |                           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the first cell with all imports for throughout \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Importing Natural Language ToolKit\n",
    "import nltk\n",
    "\n",
    "# Importing NLP essentials \n",
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# Importing CountVectorizer to tokenize our articles\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Splitting our data using train-test-split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# For applying NLP techniques\n",
    "\n",
    "\n",
    "# Modelling\n",
    "#from sklearn.linear_model import LogisiticRegression\n",
    "#from sklearn.neighbors import KNearestNeighbors\n",
    "#from sklearn.trees import DecisionTreeClassifier\n",
    "#from sklearn.neural_network import MLPClassifier \n",
    "\n",
    "\n",
    "# Metrics\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import classification_report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now covered our imports, lets move on to importing the data into the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing our True Articles \n",
    "tdf = pd.read_csv('News/True.csv')\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing our Fake Articles \n",
    "fdf = pd.read_csv('News/Fake.csv')\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make copies of our DataFrames as we don't want to make changes to the original one\n",
    "true_df = tdf.copy() # copying our true article dataframe\n",
    "fake_df = fdf.copy() # copying our fake articles dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_colwidth',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing our data\n",
    "true_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing our data\n",
    "fake_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking our True article columns\n",
    "true_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking our Fake article columns\n",
    "fake_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking our datatypes for the True CSV\n",
    "true_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking our datatypes for the Fake CSV\n",
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our data columns are all objects. Leaving the first three columns as is, we will move on to the Date column as this could give us some valuable information. We will convert the ```date``` column type from object to date time as can be seen below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the column has converted to date time, let's go ahead and split these columns into the following \n",
    "- Year\n",
    "- Month\n",
    "- Day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date column data type from object to datetime\n",
    "true_df['date'] = pd.to_datetime(true_df['date'])\n",
    "\n",
    "# Converting true_df date columns into year, month and day\n",
    "# Extracting the year of publishing\n",
    "true_df['Year'] = true_df['date'].dt.year\n",
    "\n",
    "# Extracting the month of the year\n",
    "true_df['Month'] = true_df['date'].dt.month\n",
    "\n",
    "# Extracting the day of the month\n",
    "true_df['Day of the Month'] = true_df['date'].dt.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date column data type from object to datetime\n",
    "fake_df['date'] = pd.to_datetime(fake_df['date'])\n",
    "\n",
    "# Converting fake_df date columns into year, month and day\n",
    "# Extracting the year of publishing\n",
    "fake_df['Year'] = fake_df['date'].dt.year\n",
    "\n",
    "# Extracting the month of the year\n",
    "fake_df['Month'] = fake_df['date'].dt.month\n",
    "\n",
    "# Extracting the day of the month\n",
    "fake_df['Day of the Month'] = fake_df['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                       object\n",
       "text                        object\n",
       "subject                     object\n",
       "date                datetime64[ns]\n",
       "Year                         int64\n",
       "Month                        int64\n",
       "Day of the Month             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the above has run correctly\n",
    "true_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the above has run correctly\n",
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for splitting of columns after date time split\n",
    "true_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for splitting of columns after date time split\n",
    "fake_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking for nulls in our True DataFrame\n",
    "true_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for nulls in our Fake DataFrame\n",
    "fake_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates in True DataFrame\n",
    "true_df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates in Fake DataFrame\n",
    "fake_df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the sum of duplication in our True DataFrame\n",
    "true_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the sum of duplication in our Fake DataFrame\n",
    "fake_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying unique True Articles through the title - also a sanity check for the number stated earlier\n",
    "true_df['title'].value_counts().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying unique True Articles through the title - also a sanity check for the number stated earlier\n",
    "fake_df['title'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing our True data\n",
    "true_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Describing our Fake data\n",
    "fake_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "politicsNews    11272\n",
       "worldnews       10145\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the different classes within the True DataFrame - # one hot encoding required \n",
    "true_df['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "News               9050\n",
       "politics           6841\n",
       "left-news          4459\n",
       "Government News    1570\n",
       "US_News             783\n",
       "Middle-east         778\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the different classes within the Fake DataFrame - # one hot encoding required \n",
    "fake_df['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we're going to remove all duplicated rows for both True and Fake news CSVs\n",
    "# As per our check previously, there were 206 duplicated rows in the True DataFrame while 3 in the Fake DataFrame\n",
    "# Let's remove these now\n",
    "\n",
    "# Removing duplicates from True DataFrame\n",
    "true_df.drop_duplicates(inplace = True)\n",
    "\n",
    "\n",
    "# Removing duplicates from Fake DataFrame\n",
    "fake_df.drop_duplicates(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a sanity check again for seeing if these values have been dropped in the True DataFrame\n",
    "true_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a sanity check again for seeing if these values have been dropped in the Fake DataFrame\n",
    "fake_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the observations we've made up till now are as follows:\n",
    "- 206 duplicated rows in our True (Real-News) DataFrame\n",
    "- 3 duplicated rows in our Fake (Fake-News) DataFrame\n",
    "- No null values in either of the two DataFrames\n",
    "- There were 21,417 articles for Real-News and 23,481 articles for Fake-News - after ***dropping our duplicated rows***, this has gone to 21,211 (dropped by 206) articles for Real-News and 23,478 (dropped by 3) articles for Fake-News.\n",
    "\n",
    "We've also now done some basic cleaning of the data. Let's now look at the cleaning the text data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ensure that our data is ready to be put into a model, we must do some Feature Engineering. This would include the following: \n",
    "\n",
    "- Labeling our dataset\n",
    "- One Hot Encoding our ```subject``` \n",
    "- One of the previous things we did\n",
    "-\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on to combining our two dataframes. What we must do is to do some Feature Engineering prior to combining. This would include:\n",
    "- Creating a binary classification for the different subjects we have in both true and fake articles. To keep it simple, we're going to create two classifications as follows:\n",
    "    - Political News in as 0 \n",
    "    - World News / Any other news as 1 \n",
    "    \n",
    "Give our ```true_df``` has 2 unique subjects, ***```politicsNews```*** and ***```worldnews```***, we will apply one hot encoding on this column and use the labels mentioned above (Political news as 1 and World News as 1). \n",
    "\n",
    "\n",
    "To simply it for our ```fake_df```, we will also hot encode this and reduce the number of classes, from 6, to 2 (Political news as 1 and World News as 0). \n",
    "- The following will be group as Political News (value of 1) in the ```fake_df``` dataframe:\n",
    "    - Politics\n",
    "    - Government News\n",
    "    \n",
    "- The following will be group as World News (value of 0) in the ```fake_df``` dataframe:\n",
    "    - News\n",
    "    - left-news\n",
    "    - US_News\n",
    "    - Middle-east\n",
    "   \n",
    "This can be seen below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labeling our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column of ones in the True Data Frames to identify True as class 1\n",
    "true_df['label'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column of zeros in the True Data Frames to identify True as class 0\n",
    "fake_df['label'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Renaming and reducing the multi-class classification to binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day of the Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21412</td>\n",
       "      <td>'Fully committed' NATO backs new U.S. approach...</td>\n",
       "      <td>BRUSSELS (Reuters) - NATO allies on Tuesday we...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21413</td>\n",
       "      <td>LexisNexis withdrew two products from Chinese ...</td>\n",
       "      <td>LONDON (Reuters) - LexisNexis, a provider of l...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21414</td>\n",
       "      <td>Minsk cultural hub becomes haven from authorities</td>\n",
       "      <td>MINSK (Reuters) - In the shadow of disused Sov...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21415</td>\n",
       "      <td>Vatican upbeat on possibility of Pope Francis ...</td>\n",
       "      <td>MOSCOW (Reuters) - Vatican Secretary of State ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21416</td>\n",
       "      <td>Indonesia to buy $1.14 billion worth of Russia...</td>\n",
       "      <td>JAKARTA (Reuters) - Indonesia will buy 11 Sukh...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21417 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      As U.S. budget fight looms, Republicans flip t...   \n",
       "1      U.S. military to accept transgender recruits o...   \n",
       "2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3      FBI Russia probe helped by Australian diplomat...   \n",
       "4      Trump wants Postal Service to charge 'much mor...   \n",
       "...                                                  ...   \n",
       "21412  'Fully committed' NATO backs new U.S. approach...   \n",
       "21413  LexisNexis withdrew two products from Chinese ...   \n",
       "21414  Minsk cultural hub becomes haven from authorities   \n",
       "21415  Vatican upbeat on possibility of Pope Francis ...   \n",
       "21416  Indonesia to buy $1.14 billion worth of Russia...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "0      WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1      WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2      WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3      WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4      SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "...                                                  ...           ...   \n",
       "21412  BRUSSELS (Reuters) - NATO allies on Tuesday we...     worldnews   \n",
       "21413  LONDON (Reuters) - LexisNexis, a provider of l...     worldnews   \n",
       "21414  MINSK (Reuters) - In the shadow of disused Sov...     worldnews   \n",
       "21415  MOSCOW (Reuters) - Vatican Secretary of State ...     worldnews   \n",
       "21416  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...     worldnews   \n",
       "\n",
       "            date  Year  Month  Day of the Month  \n",
       "0     2017-12-31  2017     12                31  \n",
       "1     2017-12-29  2017     12                29  \n",
       "2     2017-12-31  2017     12                31  \n",
       "3     2017-12-30  2017     12                30  \n",
       "4     2017-12-29  2017     12                29  \n",
       "...          ...   ...    ...               ...  \n",
       "21412 2017-08-22  2017      8                22  \n",
       "21413 2017-08-22  2017      8                22  \n",
       "21414 2017-08-22  2017      8                22  \n",
       "21415 2017-08-22  2017      8                22  \n",
       "21416 2017-08-22  2017      8                22  \n",
       "\n",
       "[21417 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming the columns for true_df to Politics and World News\n",
    "true_df.rename(columns = {'politicsNews' : 'Political News' , 'worldnews' : 'World News'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns and grouping together to create a binary classification for true_df\n",
    "conversion_dict_true = {'politicsNews' : 'Political News' ,\\\n",
    "                        'worldnews' : 'World News'}\n",
    "\n",
    "true_df['subject'] = true_df['subject'].map(conversion_dict_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns and grouping together to create a binary classification for fake_df\n",
    "conversion_dict_fake = {'politics' : 'Political News',\\\n",
    "                        'Government News' : 'Political News',\\\n",
    "                        'News' : 'World News',\\\n",
    "                        'left-news' : 'World News',\\\n",
    "                        'US_News' : 'World News',\\\n",
    "                        'Middle-east' : 'World News'}\n",
    "\n",
    "fake_df['subject'] = fake_df['subject'].map(conversion_dict_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Political News    11272\n",
       "World News        10145\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at how the dataframes look like now for the true_df and see the class propotions\n",
    "true_df['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "World News        15070\n",
       "Political News     8411\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at how the dataframes look like now for the fake_df and see the class propotions\n",
    "fake_df['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "ENGLISH_STOP_WORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created the two labels with True articles being (1) and False articles being 0. Let's go ahead and combined them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the two DataFrames with labels \n",
    "combined_df = pd.concat([true_df, fake_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The shape of the new combined DataFrame (combined_df) is {combined_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've gone through the process of labelling are articles and combining them into one combined dataframe as ```combined_df```, let's seperate our data into our target (label column) and features variables (rest of the columns). The label column comprises of the number which corresponds to the article being true (1) or false (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our feature variables\n",
    "X = combined_df.drop(columns = ['label'], axis = 1)\n",
    "\n",
    "# Setting our target variables\n",
    "y = combined_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our X features and y variable shape below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The shape for our features is {X.shape}')\n",
    "print(f'The shape for our target is {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've gotten to a point where we've defined our feature and target variables, it's time we move on to splitting the data into a training, validation and test set. The model will be trained on 40% of the data, validated on 30% of the data and tested on 30% of the remaining data with being stratified across all three. \n",
    "\n",
    "However, before we move on to splitting our data, it is important that we apply the tokenize our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiaing the CountVectorizer\n",
    "Bagofwords = CountVectorizer(stop_words = 'english') # insert min_df\n",
    "\n",
    "# Fitting the CountVectorizer \n",
    "Bagofwords.fit(combined_df['text'])\n",
    "\n",
    "# Transforming all of the data\n",
    "Bagofwords.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the shape of the new sparse matrix we just created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing a train-test-split, we must be careful of three different things in terms of our data:\n",
    "\n",
    "1. Stratification for class imbalances\n",
    "2. Preprocessing of our data\n",
    "3. Splitting by indices. \n",
    "\n",
    "\n",
    "The issue with splitting the data into different sets might make us lose some value of our tokens and will cause bias in our models.\n",
    "\n",
    "As we can see, up till now, we were only working with the two dataframes without having to split our data. Let's go ahead and split our data now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\\\n",
    "                                                    y,\\\n",
    "                                                    test_size = 0.3,\\\n",
    "                                                    stratify = y)\n",
    "                                                    \n",
    "    \n",
    "# Shuffling might be required too\n",
    "                                                    \n",
    "                                                    \n",
    "                                                    \n",
    "                                                    \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at how the values have been split\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Neural Network model\n",
    "\n",
    "# Fitting the Model\n",
    "\n",
    "# Scoring the model on training data \n",
    "\n",
    "# Scoring the model on validation data\n",
    "\n",
    "# Scoring the model on test data\n",
    "\n",
    "print(f'The training score using a Neural Network is: {}')\n",
    "print('\\n')\n",
    "print(f'The validation score using a Neural Network is: {}')\n",
    "print('\\n')\n",
    "print(f'The testing score using a Neural Network is: {}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the number of components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Decision Tree Classifier model\n",
    "\n",
    "# Fitting the Model\n",
    "\n",
    "# Scoring the model on training data \n",
    "\n",
    "# Scoring the model on validation data\n",
    "\n",
    "# Scoring the model on test data\n",
    "\n",
    "print(f'The training score using a Neural Network is: {}')\n",
    "print('\\n')\n",
    "print(f'The validation score using a Neural Network is: {}')\n",
    "print('\\n')\n",
    "print(f'The testing score using a Neural Network is: {}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantianing the Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the K Nearest Neighbors model\n",
    "\n",
    "# Fitting the Model\n",
    "\n",
    "# Scoring the model on training data \n",
    "\n",
    "# Scoring the model on validation data\n",
    "\n",
    "# Scoring the model on test data\n",
    "\n",
    "print(f'The training score using a Neural Network is: {}')\n",
    "print('\\n')\n",
    "print(f'The validation score using a Neural Network is: {}')\n",
    "print('\\n')\n",
    "print(f'The testing score using a Neural Network is: {}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Cross Validation model with 5 folds\n",
    "\n",
    "# Fitting the Model\n",
    "\n",
    "# Scoring the model on training data \n",
    "\n",
    "# Scoring the model on validation data\n",
    "\n",
    "# Scoring the model on test data\n",
    "\n",
    "print(f'The training score using a Neural Network is: {}')\n",
    "print('\\n')\n",
    "print(f'The validation score using a Neural Network is: {}')\n",
    "print('\\n')\n",
    "print(f'The testing score using a Neural Network is: {}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Neural Network model\n",
    "\n",
    "# Fitting the Model\n",
    "\n",
    "# Scoring the model on training data \n",
    "\n",
    "# Scoring the model on validation data\n",
    "\n",
    "# Scoring the model on test data\n",
    "\n",
    "print(f'The training score using a Neural Network is: {}')\n",
    "print('\\n')\n",
    "print(f'The validation score using a Neural Network is: {}')\n",
    "print('\\n')\n",
    "print(f'The testing score using a Neural Network is: {}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models to try\n",
    "# Decision Tree Classifier\n",
    "# KNN \n",
    "# Logisitic Regression\n",
    "# Neural Network "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
